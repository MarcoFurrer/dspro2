{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_shaded_hallucinatory_dactylology</th>\n",
       "      <th>feature_itinerant_hexahedral_photoengraver</th>\n",
       "      <th>feature_prudent_pileate_oven</th>\n",
       "      <th>feature_subalpine_apothegmatical_ajax</th>\n",
       "      <th>feature_pistachio_atypical_malison</th>\n",
       "      <th>feature_symmetrical_spongy_tricentenary</th>\n",
       "      <th>feature_ungrounded_transpontine_winder</th>\n",
       "      <th>feature_aseptic_eely_hemiplegia</th>\n",
       "      <th>...</th>\n",
       "      <th>target_teager2b_20</th>\n",
       "      <th>target_teager2b_60</th>\n",
       "      <th>target_tyler_20</th>\n",
       "      <th>target_tyler_60</th>\n",
       "      <th>target_victor_20</th>\n",
       "      <th>target_victor_60</th>\n",
       "      <th>target_waldo_20</th>\n",
       "      <th>target_waldo_60</th>\n",
       "      <th>target_xerxes_20</th>\n",
       "      <th>target_xerxes_60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n0007b5abb0c3a25</th>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n003bba8a98662e4</th>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n003bee128c2fcfc</th>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0048ac83aff7194</th>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0055a2401ba6480</th>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   era data_type  feature_shaded_hallucinatory_dactylology  \\\n",
       "id                                                                           \n",
       "n0007b5abb0c3a25  0001     train                                         3   \n",
       "n003bba8a98662e4  0001     train                                         4   \n",
       "n003bee128c2fcfc  0001     train                                         2   \n",
       "n0048ac83aff7194  0001     train                                         2   \n",
       "n0055a2401ba6480  0001     train                                         4   \n",
       "\n",
       "                  feature_itinerant_hexahedral_photoengraver  \\\n",
       "id                                                             \n",
       "n0007b5abb0c3a25                                           4   \n",
       "n003bba8a98662e4                                           2   \n",
       "n003bee128c2fcfc                                           4   \n",
       "n0048ac83aff7194                                           1   \n",
       "n0055a2401ba6480                                           1   \n",
       "\n",
       "                  feature_prudent_pileate_oven  \\\n",
       "id                                               \n",
       "n0007b5abb0c3a25                             0   \n",
       "n003bba8a98662e4                             4   \n",
       "n003bee128c2fcfc                             0   \n",
       "n0048ac83aff7194                             3   \n",
       "n0055a2401ba6480                             4   \n",
       "\n",
       "                  feature_subalpine_apothegmatical_ajax  \\\n",
       "id                                                        \n",
       "n0007b5abb0c3a25                                      3   \n",
       "n003bba8a98662e4                                      4   \n",
       "n003bee128c2fcfc                                      3   \n",
       "n0048ac83aff7194                                      0   \n",
       "n0055a2401ba6480                                      1   \n",
       "\n",
       "                  feature_pistachio_atypical_malison  \\\n",
       "id                                                     \n",
       "n0007b5abb0c3a25                                   3   \n",
       "n003bba8a98662e4                                   0   \n",
       "n003bee128c2fcfc                                   0   \n",
       "n0048ac83aff7194                                   3   \n",
       "n0055a2401ba6480                                   0   \n",
       "\n",
       "                  feature_symmetrical_spongy_tricentenary  \\\n",
       "id                                                          \n",
       "n0007b5abb0c3a25                                        1   \n",
       "n003bba8a98662e4                                        0   \n",
       "n003bee128c2fcfc                                        3   \n",
       "n0048ac83aff7194                                        0   \n",
       "n0055a2401ba6480                                        4   \n",
       "\n",
       "                  feature_ungrounded_transpontine_winder  \\\n",
       "id                                                         \n",
       "n0007b5abb0c3a25                                       1   \n",
       "n003bba8a98662e4                                       4   \n",
       "n003bee128c2fcfc                                       2   \n",
       "n0048ac83aff7194                                       3   \n",
       "n0055a2401ba6480                                       0   \n",
       "\n",
       "                  feature_aseptic_eely_hemiplegia  ...  target_teager2b_20  \\\n",
       "id                                                 ...                       \n",
       "n0007b5abb0c3a25                                0  ...                0.50   \n",
       "n003bba8a98662e4                                4  ...                0.50   \n",
       "n003bee128c2fcfc                                4  ...                1.00   \n",
       "n0048ac83aff7194                                3  ...                0.25   \n",
       "n0055a2401ba6480                                4  ...                0.50   \n",
       "\n",
       "                  target_teager2b_60  target_tyler_20  target_tyler_60  \\\n",
       "id                                                                       \n",
       "n0007b5abb0c3a25                0.50             0.25             0.25   \n",
       "n003bba8a98662e4                0.50             0.25             0.25   \n",
       "n003bee128c2fcfc                1.00             1.00             0.75   \n",
       "n0048ac83aff7194                0.25             0.25             0.25   \n",
       "n0055a2401ba6480                0.50             0.25             0.50   \n",
       "\n",
       "                  target_victor_20  target_victor_60  target_waldo_20  \\\n",
       "id                                                                      \n",
       "n0007b5abb0c3a25              0.25              0.25             0.25   \n",
       "n003bba8a98662e4              0.25              0.00             0.25   \n",
       "n003bee128c2fcfc              0.75              0.75             0.75   \n",
       "n0048ac83aff7194              0.50              0.25             0.25   \n",
       "n0055a2401ba6480              0.25              0.50             0.25   \n",
       "\n",
       "                  target_waldo_60  target_xerxes_20  target_xerxes_60  \n",
       "id                                                                     \n",
       "n0007b5abb0c3a25             0.00              0.25              0.00  \n",
       "n003bba8a98662e4             0.25              0.25              0.25  \n",
       "n003bee128c2fcfc             1.00              0.75              0.75  \n",
       "n0048ac83aff7194             0.25              0.25              0.25  \n",
       "n0055a2401ba6480             0.50              0.25              0.50  \n",
       "\n",
       "[5 rows x 2415 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.iloc[:, :-1]  # all columns except the last one\n",
    "y = df.iloc[:, -1]   # the last column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Convert object dtype columns to numeric\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train = \u001b[43mX_train\u001b[49m.apply(pd.to_numeric, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m X_test = X_test.apply(pd.to_numeric, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Convert object dtype columns to numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Assuming a regression problem\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2197016, 2413)\n",
      "X_test shape: (549254, 2413)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcofurrer/Documents/github/dspro2/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Disable GPU temporarily to avoid memory issues\n",
    "# Comment this out later if GPU works well\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Ensure reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Safer data preparation\n",
    "def prepare_data(X):\n",
    "    # Drop columns that are all NaN\n",
    "    X = X.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Convert remaining to numeric, coercing errors to NaN\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Fill NaN values with median or 0 if median fails\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().all():\n",
    "            # If all values are NaN, drop the column\n",
    "            X = X.drop(columns=[col])\n",
    "        elif X[col].isna().any():\n",
    "            # Fill NaNs with median, or 0 if median can't be calculated\n",
    "            median_val = X[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                X[col] = X[col].fillna(0)\n",
    "            else:\n",
    "                X[col] = X[col].fillna(median_val)\n",
    "    \n",
    "    return X\n",
    "\n",
    "try:\n",
    "    # Prepare data\n",
    "    X_train = prepare_data(X_train.copy())\n",
    "    X_test = prepare_data(X_test.copy())\n",
    "    \n",
    "    # Make sure test has same columns as train\n",
    "    missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test[col] = 0\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    \n",
    "    # Build smaller model\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train with smaller batch size\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=16,  # Reduced batch size\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, mae = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss (MSE): {loss:.4f}')\n",
    "    print(f'Test MAE: {mae:.4f}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
