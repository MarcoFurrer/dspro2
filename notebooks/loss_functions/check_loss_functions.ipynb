{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd5386b",
   "metadata": {},
   "source": [
    "# Loss Function Comparison: Preventing Middle Value Predictions\n",
    "\n",
    "This notebook systematically tests different loss functions to prevent models from getting stuck predicting middle values. We'll implement and compare:\n",
    "\n",
    "1. **Standard Loss Functions**: MSE, MAE, Huber\n",
    "2. **Custom Loss Functions**: Weighted MSE, Focal Loss for Regression, Quantile Loss\n",
    "3. **Penalty-based Loss Functions**: Anti-middle penalty, Diversity loss\n",
    "4. **Ensemble Approaches**: Multiple loss combinations\n",
    "\n",
    "**Goal**: Find loss functions that encourage prediction diversity while maintaining accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e572c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.losses import Loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e94303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_parquet('../../data/train_balanced.parquet')\n",
    "validation_data = pd.read_parquet('../../data/validation.parquet')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {validation_data.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "feature_cols = [col for col in train_data.columns if col != 'target']\n",
    "X_train = train_data[feature_cols].values\n",
    "y_train = train_data['target'].values\n",
    "X_val = validation_data[feature_cols].values\n",
    "y_val = validation_data['target'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(f\"Feature columns: {len(feature_cols)}\")\n",
    "print(f\"Target distribution - Train: {y_train.min():.3f} to {y_train.max():.3f}\")\n",
    "print(f\"Target distribution - Val: {y_val.min():.3f} to {y_val.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training target distribution\n",
    "axes[0,0].hist(y_train, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('Training Target Distribution')\n",
    "axes[0,0].set_xlabel('Target Value')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(y_train.mean(), color='red', linestyle='--', label=f'Mean: {y_train.mean():.3f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Validation target distribution\n",
    "axes[0,1].hist(y_val, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0,1].set_title('Validation Target Distribution')\n",
    "axes[0,1].set_xlabel('Target Value')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(y_val.mean(), color='red', linestyle='--', label=f'Mean: {y_val.mean():.3f}')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Box plots\n",
    "axes[1,0].boxplot([y_train, y_val], labels=['Train', 'Validation'])\n",
    "axes[1,0].set_title('Target Distribution Comparison')\n",
    "axes[1,0].set_ylabel('Target Value')\n",
    "\n",
    "# Percentiles analysis\n",
    "percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
    "train_percentiles = [np.percentile(y_train, p) for p in percentiles]\n",
    "val_percentiles = [np.percentile(y_val, p) for p in percentiles]\n",
    "\n",
    "axes[1,1].plot(percentiles, train_percentiles, 'o-', label='Train', linewidth=2)\n",
    "axes[1,1].plot(percentiles, val_percentiles, 's-', label='Validation', linewidth=2)\n",
    "axes[1,1].set_title('Percentile Analysis')\n",
    "axes[1,1].set_xlabel('Percentile')\n",
    "axes[1,1].set_ylabel('Target Value')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTarget Statistics:\")\n",
    "print(f\"Train - Mean: {y_train.mean():.4f}, Std: {y_train.std():.4f}\")\n",
    "print(f\"Val - Mean: {y_val.mean():.4f}, Std: {y_val.std():.4f}\")\n",
    "print(f\"\\nMiddle range (25th-75th percentile):\")\n",
    "print(f\"Train: {np.percentile(y_train, 25):.4f} - {np.percentile(y_train, 75):.4f}\")\n",
    "print(f\"Val: {np.percentile(y_val, 25):.4f} - {np.percentile(y_val, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Loss Functions\n",
    "\n",
    "class WeightedMSELoss(Loss):\n",
    "    \"\"\"MSE with higher weights for extreme values to discourage middle predictions\"\"\"\n",
    "    def __init__(self, center=0.5, extreme_weight=2.0, name=\"weighted_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.center = center\n",
    "        self.extreme_weight = extreme_weight\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate distance from center\n",
    "        distance_from_center = tf.abs(y_true - self.center)\n",
    "        # Weight: higher for values far from center\n",
    "        weights = 1.0 + self.extreme_weight * distance_from_center\n",
    "        # Weighted MSE\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(weights * mse)\n",
    "\n",
    "class FocalRegressionLoss(Loss):\n",
    "    \"\"\"Focal loss adapted for regression to focus on hard examples\"\"\"\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, name=\"focal_regression\"):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate absolute error\n",
    "        abs_error = tf.abs(y_true - y_pred)\n",
    "        # Focal weight: higher for larger errors\n",
    "        focal_weight = self.alpha * tf.pow(abs_error, self.gamma)\n",
    "        # MSE with focal weighting\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(focal_weight * mse)\n",
    "\n",
    "class AntiMiddleLoss(Loss):\n",
    "    \"\"\"Loss that penalizes predictions in the middle range\"\"\"\n",
    "    def __init__(self, center=0.5, penalty_range=0.3, penalty_strength=2.0, name=\"anti_middle\"):\n",
    "        super().__init__(name=name)\n",
    "        self.center = center\n",
    "        self.penalty_range = penalty_range\n",
    "        self.penalty_strength = penalty_strength\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Standard MSE\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        \n",
    "        # Penalty for predicting in middle range when true value is not middle\n",
    "        pred_in_middle = tf.abs(y_pred - self.center) < self.penalty_range\n",
    "        true_not_middle = tf.abs(y_true - self.center) >= self.penalty_range\n",
    "        \n",
    "        # Apply penalty when predicting middle but truth is not middle\n",
    "        penalty_mask = tf.logical_and(pred_in_middle, true_not_middle)\n",
    "        penalty = tf.where(penalty_mask, self.penalty_strength, 1.0)\n",
    "        \n",
    "        return tf.reduce_mean(penalty * mse)\n",
    "\n",
    "class QuantileLoss(Loss):\n",
    "    \"\"\"Quantile loss to encourage diverse predictions\"\"\"\n",
    "    def __init__(self, quantiles=[0.1, 0.5, 0.9], name=\"quantile\"):\n",
    "        super().__init__(name=name)\n",
    "        self.quantiles = quantiles\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # For simplicity, use asymmetric loss encouraging spread\n",
    "        errors = y_true - y_pred\n",
    "        # Asymmetric penalty\n",
    "        loss = tf.where(errors >= 0, 0.7 * tf.abs(errors), 1.3 * tf.abs(errors))\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "class DiversityLoss(Loss):\n",
    "    \"\"\"Loss that encourages prediction diversity within batches\"\"\"\n",
    "    def __init__(self, diversity_weight=0.1, name=\"diversity\"):\n",
    "        super().__init__(name=name)\n",
    "        self.diversity_weight = diversity_weight\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Standard MSE\n",
    "        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        \n",
    "        # Diversity penalty: encourage variance in predictions\n",
    "        pred_var = tf.reduce_mean(tf.square(y_pred - tf.reduce_mean(y_pred)))\n",
    "        diversity_bonus = -self.diversity_weight * pred_var  # Negative to encourage diversity\n",
    "        \n",
    "        return mse + diversity_bonus\n",
    "\n",
    "# Standard loss functions for comparison\n",
    "def get_loss_functions():\n",
    "    return {\n",
    "        'mse': 'mse',\n",
    "        'mae': 'mae', \n",
    "        'huber': tf.keras.losses.Huber(delta=0.1),\n",
    "        'weighted_mse': WeightedMSELoss(center=0.5, extreme_weight=2.0),\n",
    "        'focal_regression': FocalRegressionLoss(alpha=1.0, gamma=2.0),\n",
    "        'anti_middle': AntiMiddleLoss(center=0.5, penalty_range=0.3, penalty_strength=2.0),\n",
    "        'quantile': QuantileLoss(),\n",
    "        'diversity': DiversityLoss(diversity_weight=0.1)\n",
    "    }\n",
    "\n",
    "print(\"Custom loss functions defined:\")\n",
    "for name in get_loss_functions().keys():\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ec55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, loss_function, learning_rate=0.001):\n",
    "    \"\"\"Create a neural network model with specified loss function\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output in [0,1] range\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(loss_name, loss_function, X_train, y_train, X_val, y_val, epochs=50, verbose=0):\n",
    "    \"\"\"Train model with specific loss function and return results\"\"\"\n",
    "    print(f\"\\nTraining model with {loss_name} loss...\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(X_train.shape[1], loss_function)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train, verbose=0).flatten()\n",
    "    val_pred = model.predict(X_val, verbose=0).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    val_mse = mean_squared_error(y_val, val_pred)\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    val_mae = mean_absolute_error(y_val, val_pred)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    val_r2 = r2_score(y_val, val_pred)\n",
    "    \n",
    "    # Calculate prediction diversity metrics\n",
    "    train_pred_std = np.std(train_pred)\n",
    "    val_pred_std = np.std(val_pred)\n",
    "    train_pred_range = np.max(train_pred) - np.min(train_pred)\n",
    "    val_pred_range = np.max(val_pred) - np.min(val_pred)\n",
    "    \n",
    "    # Calculate middle clustering metric (percentage of predictions in middle 50%)\n",
    "    middle_lower = np.percentile(y_train, 25)\n",
    "    middle_upper = np.percentile(y_train, 75)\n",
    "    train_middle_pct = np.mean((train_pred >= middle_lower) & (train_pred <= middle_upper)) * 100\n",
    "    val_middle_pct = np.mean((val_pred >= middle_lower) & (val_pred <= middle_upper)) * 100\n",
    "    \n",
    "    results = {\n",
    "        'loss_name': loss_name,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'train_pred': train_pred,\n",
    "        'val_pred': val_pred,\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse,\n",
    "        'train_mae': train_mae,\n",
    "        'val_mae': val_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'val_r2': val_r2,\n",
    "        'train_pred_std': train_pred_std,\n",
    "        'val_pred_std': val_pred_std,\n",
    "        'train_pred_range': train_pred_range,\n",
    "        'val_pred_range': val_pred_range,\n",
    "        'train_middle_pct': train_middle_pct,\n",
    "        'val_middle_pct': val_middle_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"Validation MSE: {val_mse:.4f}, Prediction Std: {val_pred_std:.4f}, Middle %: {val_middle_pct:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Model training functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different loss functions\n",
    "loss_functions = get_loss_functions()\n",
    "results = {}\n",
    "\n",
    "print(\"Starting training with different loss functions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "    try:\n",
    "        result = train_and_evaluate_model(\n",
    "            loss_name, loss_function, \n",
    "            X_train_scaled, y_train, \n",
    "            X_val_scaled, y_val,\n",
    "            epochs=100, verbose=0\n",
    "        )\n",
    "        results[loss_name] = result\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {loss_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a984b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for loss_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Loss Function': loss_name,\n",
    "        'Val MSE': result['val_mse'],\n",
    "        'Val MAE': result['val_mae'],\n",
    "        'Val R¬≤': result['val_r2'],\n",
    "        'Pred Std': result['val_pred_std'],\n",
    "        'Pred Range': result['val_pred_range'],\n",
    "        'Middle %': result['val_middle_pct']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Val MSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOSS FUNCTION COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nMetrics explanation:\")\n",
    "print(\"- Val MSE: Validation Mean Squared Error (lower is better)\")\n",
    "print(\"- Val R¬≤: R-squared score (higher is better)\")\n",
    "print(\"- Pred Std: Standard deviation of predictions (higher = more diverse)\")\n",
    "print(\"- Pred Range: Range of predictions (higher = more diverse)\")\n",
    "print(\"- Middle %: Percentage of predictions in middle 50% range (lower = less clustering)\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display results\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | MSE: {row['Val MSE']:.4f} | R¬≤: {row['Val R¬≤']:.3f} | \"\n",
    "          f\"Std: {row['Pred Std']:.3f} | Range: {row['Pred Range']:.3f} | Middle: {row['Middle %']:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a778da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction distributions\n",
    "num_losses = len(results)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (loss_name, result) in enumerate(results.items()):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot prediction distribution\n",
    "    ax.hist(result['val_pred'], bins=30, alpha=0.7, color='skyblue', \n",
    "            edgecolor='black', label='Predictions')\n",
    "    ax.hist(y_val, bins=30, alpha=0.5, color='orange', \n",
    "            edgecolor='black', label='True Values')\n",
    "    \n",
    "    ax.set_title(f'{loss_name}\\nMSE: {result[\"val_mse\"]:.4f}, Std: {result[\"val_pred_std\"]:.3f}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f\"Range: {result['val_pred_range']:.3f}\\nMiddle %: {result['val_middle_pct']:.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Prediction Distributions by Loss Function', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: True vs Predicted values\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (loss_name, result) in enumerate(results.items()):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create scatter plot\n",
    "    ax.scatter(y_val, result['val_pred'], alpha=0.6, s=20)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_val.min(), result['val_pred'].min())\n",
    "    max_val = max(y_val.max(), result['val_pred'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Add horizontal line at middle value\n",
    "    middle_val = 0.5\n",
    "    ax.axhline(y=middle_val, color='orange', linestyle=':', alpha=0.7, label='Middle Value')\n",
    "    \n",
    "    ax.set_title(f'{loss_name}\\nR¬≤: {result[\"val_r2\"]:.3f}')\n",
    "    ax.set_xlabel('True Values')\n",
    "    ax.set_ylabel('Predicted Values')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('True vs Predicted Values by Loss Function', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of anti-middle clustering performance\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANTI-MIDDLE CLUSTERING ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sort by different criteria\n",
    "print(\"\\n1. LOWEST MIDDLE CLUSTERING (Best for avoiding middle predictions):\")\n",
    "print(\"-\" * 60)\n",
    "anti_middle_ranking = comparison_df.sort_values('Middle %')\n",
    "for idx, row in anti_middle_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Middle %: {row['Middle %']:5.1f}% | \"\n",
    "          f\"Pred Std: {row['Pred Std']:.3f} | Val MSE: {row['Val MSE']:.4f}\")\n",
    "\n",
    "print(\"\\n2. HIGHEST PREDICTION DIVERSITY (Best for varied predictions):\")\n",
    "print(\"-\" * 60)\n",
    "diversity_ranking = comparison_df.sort_values('Pred Std', ascending=False)\n",
    "for idx, row in diversity_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Pred Std: {row['Pred Std']:.3f} | \"\n",
    "          f\"Range: {row['Pred Range']:.3f} | Val MSE: {row['Val MSE']:.4f}\")\n",
    "\n",
    "print(\"\\n3. BEST BALANCE (Low MSE + Low Middle Clustering):\")\n",
    "print(\"-\" * 60)\n",
    "# Create composite score: normalize metrics and combine\n",
    "comparison_df['MSE_norm'] = (comparison_df['Val MSE'] - comparison_df['Val MSE'].min()) / (comparison_df['Val MSE'].max() - comparison_df['Val MSE'].min())\n",
    "comparison_df['Middle_norm'] = (comparison_df['Middle %'] - comparison_df['Middle %'].min()) / (comparison_df['Middle %'].max() - comparison_df['Middle %'].min())\n",
    "comparison_df['Composite_Score'] = comparison_df['MSE_norm'] + comparison_df['Middle_norm']  # Lower is better\n",
    "\n",
    "balanced_ranking = comparison_df.sort_values('Composite_Score')\n",
    "for idx, row in balanced_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Composite: {row['Composite_Score']:.3f} | \"\n",
    "          f\"MSE: {row['Val MSE']:.4f} | Middle %: {row['Middle %']:5.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. MSE vs Middle Clustering\n",
    "axes[0,0].scatter(comparison_df['Middle %'], comparison_df['Val MSE'], s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    axes[0,0].annotate(row['Loss Function'], \n",
    "                      (row['Middle %'], row['Val MSE']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "axes[0,0].set_xlabel('Middle Clustering %')\n",
    "axes[0,0].set_ylabel('Validation MSE')\n",
    "axes[0,0].set_title('MSE vs Middle Clustering\\n(Lower left is better)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Prediction Diversity vs Accuracy\n",
    "axes[0,1].scatter(comparison_df['Pred Std'], comparison_df['Val R¬≤'], s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    axes[0,1].annotate(row['Loss Function'], \n",
    "                      (row['Pred Std'], row['Val R¬≤']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "axes[0,1].set_xlabel('Prediction Standard Deviation')\n",
    "axes[0,1].set_ylabel('Validation R¬≤')\n",
    "axes[0,1].set_title('Prediction Diversity vs Accuracy\\n(Upper right is better)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Ranking comparison\n",
    "loss_names = comparison_df['Loss Function'].tolist()\n",
    "y_pos = np.arange(len(loss_names))\n",
    "\n",
    "axes[1,0].barh(y_pos, comparison_df['Middle %'], alpha=0.7, color='coral')\n",
    "axes[1,0].set_yticks(y_pos)\n",
    "axes[1,0].set_yticklabels(loss_names)\n",
    "axes[1,0].set_xlabel('Middle Clustering %')\n",
    "axes[1,0].set_title('Middle Clustering by Loss Function\\n(Lower is better)')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Composite score ranking\n",
    "balanced_ranking_display = balanced_ranking.copy()\n",
    "axes[1,1].barh(y_pos, balanced_ranking_display['Composite_Score'], alpha=0.7, color='lightblue')\n",
    "axes[1,1].set_yticks(y_pos)\n",
    "axes[1,1].set_yticklabels(balanced_ranking_display['Loss Function'])\n",
    "axes[1,1].set_xlabel('Composite Score (MSE + Middle %)')\n",
    "axes[1,1].set_title('Overall Performance Ranking\\n(Lower is better)')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS TO PREVENT MIDDLE VALUE CLUSTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get best performers in each category\n",
    "best_anti_middle = anti_middle_ranking.iloc[0]\n",
    "best_diversity = diversity_ranking.iloc[0]\n",
    "best_balanced = balanced_ranking.iloc[0]\n",
    "\n",
    "print(\"\\nüéØ TOP RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"\\n1. BEST ANTI-MIDDLE CLUSTERING: {best_anti_middle['Loss Function']}\")\n",
    "print(f\"   - Middle clustering: {best_anti_middle['Middle %']:.1f}%\")\n",
    "print(f\"   - Validation MSE: {best_anti_middle['Val MSE']:.4f}\")\n",
    "print(f\"   - Prediction diversity: {best_anti_middle['Pred Std']:.3f}\")\n",
    "\n",
    "print(f\"\\n2. HIGHEST PREDICTION DIVERSITY: {best_diversity['Loss Function']}\")\n",
    "print(f\"   - Prediction std: {best_diversity['Pred Std']:.3f}\")\n",
    "print(f\"   - Prediction range: {best_diversity['Pred Range']:.3f}\")\n",
    "print(f\"   - Validation MSE: {best_diversity['Val MSE']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. BEST OVERALL BALANCE: {best_balanced['Loss Function']}\")\n",
    "print(f\"   - Composite score: {best_balanced['Composite_Score']:.3f}\")\n",
    "print(f\"   - Validation MSE: {best_balanced['Val MSE']:.4f}\")\n",
    "print(f\"   - Middle clustering: {best_balanced['Middle %']:.1f}%\")\n",
    "\n",
    "print(\"\\nüìã IMPLEMENTATION STRATEGIES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\\n‚Ä¢ Use weighted MSE with higher weights for extreme values\")\n",
    "print(\"‚Ä¢ Implement anti-middle penalty in loss function\")\n",
    "print(\"‚Ä¢ Add diversity regularization to encourage prediction spread\")\n",
    "print(\"‚Ä¢ Consider focal loss for focusing on hard examples\")\n",
    "print(\"‚Ä¢ Experiment with quantile loss for asymmetric penalties\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  KEY INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚Ä¢ Standard MSE tends to produce middle-clustered predictions\")\n",
    "print(\"‚Ä¢ Custom loss functions can significantly reduce middle clustering\")\n",
    "print(\"‚Ä¢ There's often a trade-off between accuracy and prediction diversity\")\n",
    "print(\"‚Ä¢ Weighted and penalty-based losses show most promise\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚Ä¢ Fine-tune the best-performing loss function hyperparameters\")\n",
    "print(\"‚Ä¢ Test ensemble methods combining multiple loss functions\")\n",
    "print(\"‚Ä¢ Implement data augmentation techniques\")\n",
    "print(\"‚Ä¢ Consider architectural changes (e.g., multiple output heads)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad85b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and best models\n",
    "print(\"\\nSaving results and best models...\")\n",
    "\n",
    "# Save comparison results to CSV\n",
    "comparison_df.to_csv('../../data/loss_function_comparison.csv', index=False)\n",
    "print(\"‚úÖ Comparison results saved to: data/loss_function_comparison.csv\")\n",
    "\n",
    "# Save the best model from each category\n",
    "best_models = {\n",
    "    'anti_middle': best_anti_middle['Loss Function'],\n",
    "    'diversity': best_diversity['Loss Function'], \n",
    "    'balanced': best_balanced['Loss Function']\n",
    "}\n",
    "\n",
    "for category, loss_name in best_models.items():\n",
    "    if loss_name in results:\n",
    "        model_path = f'../../exports/best_{category}_{loss_name}.keras'\n",
    "        results[loss_name]['model'].save(model_path)\n",
    "        print(f\"‚úÖ Best {category} model ({loss_name}) saved to: {model_path}\")\n",
    "\n",
    "print(\"\\nüìä FINAL SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚Ä¢ Tested {len(results)} different loss functions\")\n",
    "print(f\"‚Ä¢ Best anti-middle: {best_anti_middle['Loss Function']} ({best_anti_middle['Middle %']:.1f}% clustering)\")\n",
    "print(f\"‚Ä¢ Most diverse: {best_diversity['Loss Function']} (std: {best_diversity['Pred Std']:.3f})\")\n",
    "print(f\"‚Ä¢ Best balanced: {best_balanced['Loss Function']} (score: {best_balanced['Composite_Score']:.3f})\")\n",
    "print(\"\\nüéâ Loss function analysis completed successfully!\")\n",
    "print(\"\\nUse the saved models and insights to improve your prediction diversity.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
