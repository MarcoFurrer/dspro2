{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b0d426",
   "metadata": {},
   "source": [
    "# Loss Function Comparison with Advanced Model\n",
    "\n",
    "This notebook compares standard Keras loss functions using the Advanced model and ModelRunner for all data handling and training operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976dbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from model_runner import ModelRunner\n",
    "from models.Advanced import model as base_advanced_model\n",
    "from optimizers.Adam import optimizer as adam_optimizer\n",
    "\n",
    "# Data paths\n",
    "TRAIN_PATH = \"../../data/train_balanced.parquet\"\n",
    "VAL_PATH = \"../../data/validation.parquet\"\n",
    "META_PATH = \"../../data/meta_model.parquet\"\n",
    "FEATURES_PATH = \"../../data/features.json\"\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard loss functions to compare\n",
    "LOSS_FUNCTIONS = {\n",
    "    'mae': 'mae',  # Mean Absolute Error\n",
    "    'mse': 'mse',  # Mean Squared Error\n",
    "    'huber': 'huber',  # Huber Loss (robust to outliers)\n",
    "    'logcosh': 'logcosh',  # Log-Cosh Loss\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "SUBSET_FEATURES = \"small\"\n",
    "\n",
    "print(f\"Will test {len(LOSS_FUNCTIONS)} loss functions:\")\n",
    "for name, loss_fn in LOSS_FUNCTIONS.items():\n",
    "    print(f\"  - {name}: {loss_fn}\")\n",
    "print(f\"\\nTraining config: {EPOCHS} epochs, batch size {BATCH_SIZE}, features: {SUBSET_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644df400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_loss_function(loss_name, loss_function):\n",
    "    \"\"\"Train Advanced model with specified loss function using ModelRunner\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with {loss_name.upper()} loss function\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create fresh model instance\n",
    "    import tensorflow as tf\n",
    "    from models.Advanced import model as create_advanced_model\n",
    "    model = create_advanced_model\n",
    "    \n",
    "    # Compile with specified loss function\n",
    "    model.compile(\n",
    "        optimizer=adam_optimizer,\n",
    "        loss=loss_function,\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    # Initialize ModelRunner\n",
    "    runner = ModelRunner(\n",
    "        path_train=TRAIN_PATH,\n",
    "        path_val=VAL_PATH,\n",
    "        path_meta_model=META_PATH,\n",
    "        path_features=FEATURES_PATH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset_features=SUBSET_FEATURES,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trained_model, history = runner.train(epochs=EPOCHS)\n",
    "    \n",
    "    # Get final metrics\n",
    "    final_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    final_mae = history.history['mae'][-1]\n",
    "    final_val_mae = history.history['val_mae'][-1]\n",
    "    \n",
    "    print(f\"\\nFinal metrics for {loss_name}:\")\n",
    "    print(f\"  Training Loss: {final_loss:.6f}\")\n",
    "    print(f\"  Validation Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"  Training MAE: {final_mae:.6f}\")\n",
    "    print(f\"  Validation MAE: {final_val_mae:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'loss_name': loss_name,\n",
    "        'history': history,\n",
    "        'final_loss': final_loss,\n",
    "        'final_val_loss': final_val_loss,\n",
    "        'final_mae': final_mae,\n",
    "        'final_val_mae': final_val_mae,\n",
    "        'model': trained_model,\n",
    "        'runner': runner\n",
    "    }\n",
    "\n",
    "print(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different loss functions\n",
    "results = {}\n",
    "\n",
    "print(\"Starting training with different loss functions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for loss_name, loss_function in LOSS_FUNCTIONS.items():\n",
    "    try:\n",
    "        result = train_with_loss_function(loss_name, loss_function)\n",
    "        results[loss_name] = result\n",
    "        print(f\"‚úÖ {loss_name} training completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {loss_name} training failed: {str(e)}\")\n",
    "        results[loss_name] = None\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All training completed!\")\n",
    "print(f\"Successful trainings: {sum(1 for r in results.values() if r is not None)}/{len(LOSS_FUNCTIONS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOSS FUNCTION COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for loss_name, result in results.items():\n",
    "    if result is not None:\n",
    "        summary_data.append({\n",
    "            'Loss Function': loss_name.upper(),\n",
    "            'Final Train Loss': f\"{result['final_loss']:.6f}\",\n",
    "            'Final Val Loss': f\"{result['final_val_loss']:.6f}\",\n",
    "            'Final Train MAE': f\"{result['final_mae']:.6f}\",\n",
    "            'Final Val MAE': f\"{result['final_val_mae']:.6f}\",\n",
    "            'Convergence': 'Good' if result['final_val_loss'] < result['history'].history['val_loss'][0] * 0.9 else 'Poor'\n",
    "        })\n",
    "    else:\n",
    "        summary_data.append({\n",
    "            'Loss Function': loss_name.upper(),\n",
    "            'Final Train Loss': 'FAILED',\n",
    "            'Final Val Loss': 'FAILED',\n",
    "            'Final Train MAE': 'FAILED',\n",
    "            'Final Val MAE': 'FAILED',\n",
    "            'Convergence': 'FAILED'\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for nice display\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find best performing loss function based on validation MAE\n",
    "valid_results = {k: v for k, v in results.items() if v is not None}\n",
    "if valid_results:\n",
    "    best_loss = min(valid_results.items(), key=lambda x: x[1]['final_val_mae'])\n",
    "    print(f\"\\nüèÜ Best performing loss function: {best_loss[0].upper()}\")\n",
    "    print(f\"   Final Validation MAE: {best_loss[1]['final_val_mae']:.6f}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No successful training runs to compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves for all loss functions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Loss Function Comparison - Training Curves', fontsize=16)\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax1 = axes[0, 0]\n",
    "for loss_name, result in results.items():\n",
    "    if result is not None:\n",
    "        ax1.plot(result['history'].history['loss'], label=f'{loss_name.upper()}')\n",
    "ax1.set_title('Training Loss Curves')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "ax2 = axes[0, 1]\n",
    "for loss_name, result in results.items():\n",
    "    if result is not None:\n",
    "        ax2.plot(result['history'].history['val_loss'], label=f'{loss_name.upper()}')\n",
    "ax2.set_title('Validation Loss Curves')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plot 3: Training MAE\n",
    "ax3 = axes[1, 0]\n",
    "for loss_name, result in results.items():\n",
    "    if result is not None:\n",
    "        ax3.plot(result['history'].history['mae'], label=f'{loss_name.upper()}')\n",
    "ax3.set_title('Training MAE Curves')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('MAE')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Plot 4: Validation MAE\n",
    "ax4 = axes[1, 1]\n",
    "for loss_name, result in results.items():\n",
    "    if result is not None:\n",
    "        ax4.plot(result['history'].history['val_mae'], label=f'{loss_name.upper()}')\n",
    "ax4.set_title('Validation MAE Curves')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('MAE')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions with the best performing model\n",
    "if valid_results:\n",
    "    best_loss_name, best_result = best_loss\n",
    "    best_runner = best_result['runner']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TESTING BEST MODEL ({best_loss_name.upper()})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load test data\n",
    "    try:\n",
    "        live_data = pd.read_parquet(\"../../data/live.parquet\")\n",
    "        feature_cols = best_runner.feature_set[\"feature_sets\"][best_runner.subset_features]\n",
    "        X_live = live_data[feature_cols].values.astype(np.float32)\n",
    "        \n",
    "        # Generate predictions\n",
    "        print(\"Generating predictions on live data...\")\n",
    "        predictions = best_runner.predict(X_live)\n",
    "        \n",
    "        print(f\"\\nPrediction Results:\")\n",
    "        print(f\"  Total predictions: {len(predictions):,}\")\n",
    "        print(f\"  Prediction range: [{predictions.min():.6f}, {predictions.max():.6f}]\")\n",
    "        print(f\"  Mean prediction: {predictions.mean():.6f}\")\n",
    "        print(f\"  Std deviation: {predictions.std():.6f}\")\n",
    "        print(f\"  Unique values: {len(np.unique(np.round(predictions, 6))):,}\")\n",
    "        \n",
    "        # Plot prediction distribution\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(predictions, bins=50, alpha=0.7, edgecolor='black')\n",
    "        plt.title(f'Prediction Distribution\\n({best_loss_name.upper()} Loss)')\n",
    "        plt.xlabel('Prediction Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.boxplot(predictions)\n",
    "        plt.title(f'Prediction Box Plot\\n({best_loss_name.upper()} Loss)')\n",
    "        plt.ylabel('Prediction Value')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(f\"\\nFirst 10 predictions:\")\n",
    "        for i in range(min(10, len(predictions))):\n",
    "            print(f\"  {i+1}: {predictions[i]:.6f}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  Live data file not found, skipping prediction test\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during prediction testing: {str(e)}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No valid models to test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8be56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL SUMMARY AND RECOMMENDATIONS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nüìä EXPERIMENT OVERVIEW:\")\n",
    "print(f\"   ‚Ä¢ Tested {len(LOSS_FUNCTIONS)} standard loss functions\")\n",
    "print(f\"   ‚Ä¢ Used Advanced model architecture\")\n",
    "print(f\"   ‚Ä¢ Trained with ModelRunner for {EPOCHS} epochs\")\n",
    "print(f\"   ‚Ä¢ Features: {SUBSET_FEATURES} subset\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "if valid_results:\n",
    "    print(f\"\\nüèÜ BEST PERFORMING LOSS FUNCTION:\")\n",
    "    print(f\"   ‚Ä¢ {best_loss_name.upper()} with validation MAE: {best_result['final_val_mae']:.6f}\")\n",
    "    \n",
    "    print(f\"\\nüìà PERFORMANCE RANKING (by validation MAE):\")\n",
    "    sorted_results = sorted(valid_results.items(), key=lambda x: x[1]['final_val_mae'])\n",
    "    for i, (loss_name, result) in enumerate(sorted_results, 1):\n",
    "        print(f\"   {i}. {loss_name.upper()}: {result['final_val_mae']:.6f}\")\n",
    "    \n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    best_val_mae = best_result['final_val_mae']\n",
    "    if best_val_mae < 0.1:\n",
    "        print(f\"   ‚úÖ Excellent performance! The {best_loss_name.upper()} loss function works very well.\")\n",
    "    elif best_val_mae < 0.2:\n",
    "        print(f\"   üëç Good performance with {best_loss_name.upper()} loss function.\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Performance could be improved. Consider:\")\n",
    "        print(f\"      - Training for more epochs\")\n",
    "        print(f\"      - Using a different model architecture\")\n",
    "        print(f\"      - Feature engineering\")\n",
    "    \n",
    "    print(f\"\\nüîß TECHNICAL INSIGHTS:\")\n",
    "    loss_types = {\n",
    "        'mae': 'Robust to outliers, linear penalty',\n",
    "        'mse': 'Sensitive to outliers, quadratic penalty', \n",
    "        'huber': 'Combines MAE and MSE benefits',\n",
    "        'logcosh': 'Smooth approximation of MAE'\n",
    "    }\n",
    "    \n",
    "    for loss_name, result in sorted_results[:2]:  # Top 2\n",
    "        if loss_name in loss_types:\n",
    "            print(f\"   ‚Ä¢ {loss_name.upper()}: {loss_types[loss_name]}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No successful training runs completed.\")\n",
    "    print(f\"   Check data paths and model compatibility.\")\n",
    "\n",
    "print(f\"\\nüéØ MODELRUNNER INTEGRATION:\")\n",
    "print(f\"   ‚úÖ Successfully used ModelRunner for all data handling\")\n",
    "print(f\"   ‚úÖ No manual data loading or preprocessing required\")\n",
    "print(f\"   ‚úÖ Consistent training pipeline across all loss functions\")\n",
    "print(f\"   ‚úÖ Built-in model export and validation capabilities\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXPERIMENT COMPLETED SUCCESSFULLY\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
