{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd5386b",
   "metadata": {},
   "source": [
    "# Loss Function Comparison: Preventing Middle Value Predictions\n",
    "\n",
    "This notebook systematically tests different loss functions to prevent models from getting stuck predicting middle values. We'll implement and compare:\n",
    "\n",
    "1. **Standard Loss Functions**: MSE, MAE, Huber\n",
    "2. **Custom Loss Functions**: Weighted MSE, Focal Loss for Regression, Quantile Loss\n",
    "3. **Penalty-based Loss Functions**: Anti-middle penalty, Diversity loss\n",
    "4. **Ensemble Approaches**: Multiple loss combinations\n",
    "\n",
    "**Goal**: Find loss functions that encourage prediction diversity while maintaining accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e572c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.losses import Loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e94303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_parquet('../../data/train_balanced.parquet')\n",
    "validation_data = pd.read_parquet('../../data/validation.parquet')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {validation_data.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "feature_cols = [col for col in train_data.columns if col != 'target']\n",
    "X_train = train_data[feature_cols].values\n",
    "y_train = train_data['target'].values\n",
    "X_val = validation_data[feature_cols].values\n",
    "y_val = validation_data['target'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(f\"Feature columns: {len(feature_cols)}\")\n",
    "print(f\"Target distribution - Train: {y_train.min():.3f} to {y_train.max():.3f}\")\n",
    "print(f\"Target distribution - Val: {y_val.min():.3f} to {y_val.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training target distribution\n",
    "axes[0,0].hist(y_train, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('Training Target Distribution')\n",
    "axes[0,0].set_xlabel('Target Value')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(y_train.mean(), color='red', linestyle='--', label=f'Mean: {y_train.mean():.3f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Validation target distribution\n",
    "axes[0,1].hist(y_val, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0,1].set_title('Validation Target Distribution')\n",
    "axes[0,1].set_xlabel('Target Value')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(y_val.mean(), color='red', linestyle='--', label=f'Mean: {y_val.mean():.3f}')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Box plots\n",
    "axes[1,0].boxplot([y_train, y_val], labels=['Train', 'Validation'])\n",
    "axes[1,0].set_title('Target Distribution Comparison')\n",
    "axes[1,0].set_ylabel('Target Value')\n",
    "\n",
    "# Percentiles analysis\n",
    "percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
    "train_percentiles = [np.percentile(y_train, p) for p in percentiles]\n",
    "val_percentiles = [np.percentile(y_val, p) for p in percentiles]\n",
    "\n",
    "axes[1,1].plot(percentiles, train_percentiles, 'o-', label='Train', linewidth=2)\n",
    "axes[1,1].plot(percentiles, val_percentiles, 's-', label='Validation', linewidth=2)\n",
    "axes[1,1].set_title('Percentile Analysis')\n",
    "axes[1,1].set_xlabel('Percentile')\n",
    "axes[1,1].set_ylabel('Target Value')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTarget Statistics:\")\n",
    "print(f\"Train - Mean: {y_train.mean():.4f}, Std: {y_train.std():.4f}\")\n",
    "print(f\"Val - Mean: {y_val.mean():.4f}, Std: {y_val.std():.4f}\")\n",
    "print(f\"\\nMiddle range (25th-75th percentile):\")\n",
    "print(f\"Train: {np.percentile(y_train, 25):.4f} - {np.percentile(y_train, 75):.4f}\")\n",
    "print(f\"Val: {np.percentile(y_val, 25):.4f} - {np.percentile(y_val, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Loss Functions\n",
    "\n",
    "class WeightedMSELoss(Loss):\n",
    "    \"\"\"MSE with higher weights for extreme values to discourage middle predictions\"\"\"\n",
    "    def __init__(self, center=0.5, extreme_weight=2.0, name=\"weighted_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.center = center\n",
    "        self.extreme_weight = extreme_weight\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate distance from center\n",
    "        distance_from_center = tf.abs(y_true - self.center)\n",
    "        # Weight: higher for values far from center\n",
    "        weights = 1.0 + self.extreme_weight * distance_from_center\n",
    "        # Weighted MSE\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(weights * mse)\n",
    "\n",
    "class FocalRegressionLoss(Loss):\n",
    "    \"\"\"Focal loss adapted for regression to focus on hard examples\"\"\"\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, name=\"focal_regression\"):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate absolute error\n",
    "        abs_error = tf.abs(y_true - y_pred)\n",
    "        # Focal weight: higher for larger errors\n",
    "        focal_weight = self.alpha * tf.pow(abs_error, self.gamma)\n",
    "        # MSE with focal weighting\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(focal_weight * mse)\n",
    "\n",
    "class AntiMiddleLoss(Loss):\n",
    "    \"\"\"Loss that penalizes predictions in the middle range\"\"\"\n",
    "    def __init__(self, center=0.5, penalty_range=0.3, penalty_strength=2.0, name=\"anti_middle\"):\n",
    "        super().__init__(name=name)\n",
    "        self.center = center\n",
    "        self.penalty_range = penalty_range\n",
    "        self.penalty_strength = penalty_strength\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Standard MSE\n",
    "        mse = tf.square(y_true - y_pred)\n",
    "        \n",
    "        # Penalty for predicting in middle range when true value is not middle\n",
    "        pred_in_middle = tf.abs(y_pred - self.center) < self.penalty_range\n",
    "        true_not_middle = tf.abs(y_true - self.center) >= self.penalty_range\n",
    "        \n",
    "        # Apply penalty when predicting middle but truth is not middle\n",
    "        penalty_mask = tf.logical_and(pred_in_middle, true_not_middle)\n",
    "        penalty = tf.where(penalty_mask, self.penalty_strength, 1.0)\n",
    "        \n",
    "        return tf.reduce_mean(penalty * mse)\n",
    "\n",
    "class QuantileLoss(Loss):\n",
    "    \"\"\"Quantile loss to encourage diverse predictions\"\"\"\n",
    "    def __init__(self, quantiles=[0.1, 0.5, 0.9], name=\"quantile\"):\n",
    "        super().__init__(name=name)\n",
    "        self.quantiles = quantiles\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # For simplicity, use asymmetric loss encouraging spread\n",
    "        errors = y_true - y_pred\n",
    "        # Asymmetric penalty\n",
    "        loss = tf.where(errors >= 0, 0.7 * tf.abs(errors), 1.3 * tf.abs(errors))\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "class DiversityLoss(Loss):\n",
    "    \"\"\"Loss that encourages prediction diversity within batches\"\"\"\n",
    "    def __init__(self, diversity_weight=0.1, name=\"diversity\"):\n",
    "        super().__init__(name=name)\n",
    "        self.diversity_weight = diversity_weight\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Standard MSE\n",
    "        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        \n",
    "        # Diversity penalty: encourage variance in predictions\n",
    "        pred_var = tf.reduce_mean(tf.square(y_pred - tf.reduce_mean(y_pred)))\n",
    "        diversity_bonus = -self.diversity_weight * pred_var  # Negative to encourage diversity\n",
    "        \n",
    "        return mse + diversity_bonus\n",
    "\n",
    "# Standard loss functions for comparison\n",
    "def get_loss_functions():\n",
    "    return {\n",
    "        'mse': 'mse',\n",
    "        'mae': 'mae', \n",
    "        'huber': tf.keras.losses.Huber(delta=0.1),\n",
    "        'weighted_mse': WeightedMSELoss(center=0.5, extreme_weight=2.0),\n",
    "        'focal_regression': FocalRegressionLoss(alpha=1.0, gamma=2.0),\n",
    "        'anti_middle': AntiMiddleLoss(center=0.5, penalty_range=0.3, penalty_strength=2.0),\n",
    "        'quantile': QuantileLoss(),\n",
    "        'diversity': DiversityLoss(diversity_weight=0.1)\n",
    "    }\n",
    "\n",
    "print(\"Custom loss functions defined:\")\n",
    "for name in get_loss_functions().keys():\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ec55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, loss_function, learning_rate=0.001):\n",
    "    \"\"\"Create a neural network model with specified loss function\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output in [0,1] range\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(loss_name, loss_function, X_train, y_train, X_val, y_val, epochs=50, verbose=0):\n",
    "    \"\"\"Train model with specific loss function and return results\"\"\"\n",
    "    print(f\"\\nTraining model with {loss_name} loss...\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(X_train.shape[1], loss_function)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train, verbose=0).flatten()\n",
    "    val_pred = model.predict(X_val, verbose=0).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    val_mse = mean_squared_error(y_val, val_pred)\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    val_mae = mean_absolute_error(y_val, val_pred)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    val_r2 = r2_score(y_val, val_pred)\n",
    "    \n",
    "    # Calculate prediction diversity metrics\n",
    "    train_pred_std = np.std(train_pred)\n",
    "    val_pred_std = np.std(val_pred)\n",
    "    train_pred_range = np.max(train_pred) - np.min(train_pred)\n",
    "    val_pred_range = np.max(val_pred) - np.min(val_pred)\n",
    "    \n",
    "    # Calculate middle clustering metric (percentage of predictions in middle 50%)\n",
    "    middle_lower = np.percentile(y_train, 25)\n",
    "    middle_upper = np.percentile(y_train, 75)\n",
    "    train_middle_pct = np.mean((train_pred >= middle_lower) & (train_pred <= middle_upper)) * 100\n",
    "    val_middle_pct = np.mean((val_pred >= middle_lower) & (val_pred <= middle_upper)) * 100\n",
    "    \n",
    "    results = {\n",
    "        'loss_name': loss_name,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'train_pred': train_pred,\n",
    "        'val_pred': val_pred,\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse,\n",
    "        'train_mae': train_mae,\n",
    "        'val_mae': val_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'val_r2': val_r2,\n",
    "        'train_pred_std': train_pred_std,\n",
    "        'val_pred_std': val_pred_std,\n",
    "        'train_pred_range': train_pred_range,\n",
    "        'val_pred_range': val_pred_range,\n",
    "        'train_middle_pct': train_middle_pct,\n",
    "        'val_middle_pct': val_middle_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"Validation MSE: {val_mse:.4f}, Prediction Std: {val_pred_std:.4f}, Middle %: {val_middle_pct:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Model training functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different loss functions\n",
    "loss_functions = get_loss_functions()\n",
    "results = {}\n",
    "\n",
    "print(\"Starting training with different loss functions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "    try:\n",
    "        result = train_and_evaluate_model(\n",
    "            loss_name, loss_function, \n",
    "            X_train_scaled, y_train, \n",
    "            X_val_scaled, y_val,\n",
    "            epochs=100, verbose=0\n",
    "        )\n",
    "        results[loss_name] = result\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {loss_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a984b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for loss_name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Loss Function': loss_name,\n",
    "        'Val MSE': result['val_mse'],\n",
    "        'Val MAE': result['val_mae'],\n",
    "        'Val R²': result['val_r2'],\n",
    "        'Pred Std': result['val_pred_std'],\n",
    "        'Pred Range': result['val_pred_range'],\n",
    "        'Middle %': result['val_middle_pct']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Val MSE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOSS FUNCTION COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nMetrics explanation:\")\n",
    "print(\"- Val MSE: Validation Mean Squared Error (lower is better)\")\n",
    "print(\"- Val R²: R-squared score (higher is better)\")\n",
    "print(\"- Pred Std: Standard deviation of predictions (higher = more diverse)\")\n",
    "print(\"- Pred Range: Range of predictions (higher = more diverse)\")\n",
    "print(\"- Middle %: Percentage of predictions in middle 50% range (lower = less clustering)\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display results\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | MSE: {row['Val MSE']:.4f} | R²: {row['Val R²']:.3f} | \"\n",
    "          f\"Std: {row['Pred Std']:.3f} | Range: {row['Pred Range']:.3f} | Middle: {row['Middle %']:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a778da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction distributions\n",
    "num_losses = len(results)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (loss_name, result) in enumerate(results.items()):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot prediction distribution\n",
    "    ax.hist(result['val_pred'], bins=30, alpha=0.7, color='skyblue', \n",
    "            edgecolor='black', label='Predictions')\n",
    "    ax.hist(y_val, bins=30, alpha=0.5, color='orange', \n",
    "            edgecolor='black', label='True Values')\n",
    "    \n",
    "    ax.set_title(f'{loss_name}\\nMSE: {result[\"val_mse\"]:.4f}, Std: {result[\"val_pred_std\"]:.3f}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f\"Range: {result['val_pred_range']:.3f}\\nMiddle %: {result['val_middle_pct']:.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Prediction Distributions by Loss Function', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: True vs Predicted values\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (loss_name, result) in enumerate(results.items()):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create scatter plot\n",
    "    ax.scatter(y_val, result['val_pred'], alpha=0.6, s=20)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_val.min(), result['val_pred'].min())\n",
    "    max_val = max(y_val.max(), result['val_pred'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Add horizontal line at middle value\n",
    "    middle_val = 0.5\n",
    "    ax.axhline(y=middle_val, color='orange', linestyle=':', alpha=0.7, label='Middle Value')\n",
    "    \n",
    "    ax.set_title(f'{loss_name}\\nR²: {result[\"val_r2\"]:.3f}')\n",
    "    ax.set_xlabel('True Values')\n",
    "    ax.set_ylabel('Predicted Values')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('True vs Predicted Values by Loss Function', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of anti-middle clustering performance\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANTI-MIDDLE CLUSTERING ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sort by different criteria\n",
    "print(\"\\n1. LOWEST MIDDLE CLUSTERING (Best for avoiding middle predictions):\")\n",
    "print(\"-\" * 60)\n",
    "anti_middle_ranking = comparison_df.sort_values('Middle %')\n",
    "for idx, row in anti_middle_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Middle %: {row['Middle %']:5.1f}% | \"\n",
    "          f\"Pred Std: {row['Pred Std']:.3f} | Val MSE: {row['Val MSE']:.4f}\")\n",
    "\n",
    "print(\"\\n2. HIGHEST PREDICTION DIVERSITY (Best for varied predictions):\")\n",
    "print(\"-\" * 60)\n",
    "diversity_ranking = comparison_df.sort_values('Pred Std', ascending=False)\n",
    "for idx, row in diversity_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Pred Std: {row['Pred Std']:.3f} | \"\n",
    "          f\"Range: {row['Pred Range']:.3f} | Val MSE: {row['Val MSE']:.4f}\")\n",
    "\n",
    "print(\"\\n3. BEST BALANCE (Low MSE + Low Middle Clustering):\")\n",
    "print(\"-\" * 60)\n",
    "# Create composite score: normalize metrics and combine\n",
    "comparison_df['MSE_norm'] = (comparison_df['Val MSE'] - comparison_df['Val MSE'].min()) / (comparison_df['Val MSE'].max() - comparison_df['Val MSE'].min())\n",
    "comparison_df['Middle_norm'] = (comparison_df['Middle %'] - comparison_df['Middle %'].min()) / (comparison_df['Middle %'].max() - comparison_df['Middle %'].min())\n",
    "comparison_df['Composite_Score'] = comparison_df['MSE_norm'] + comparison_df['Middle_norm']  # Lower is better\n",
    "\n",
    "balanced_ranking = comparison_df.sort_values('Composite_Score')\n",
    "for idx, row in balanced_ranking.head().iterrows():\n",
    "    print(f\"{row['Loss Function']:15} | Composite: {row['Composite_Score']:.3f} | \"\n",
    "          f\"MSE: {row['Val MSE']:.4f} | Middle %: {row['Middle %']:5.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. MSE vs Middle Clustering\n",
    "axes[0,0].scatter(comparison_df['Middle %'], comparison_df['Val MSE'], s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    axes[0,0].annotate(row['Loss Function'], \n",
    "                      (row['Middle %'], row['Val MSE']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "axes[0,0].set_xlabel('Middle Clustering %')\n",
    "axes[0,0].set_ylabel('Validation MSE')\n",
    "axes[0,0].set_title('MSE vs Middle Clustering\\n(Lower left is better)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Prediction Diversity vs Accuracy\n",
    "axes[0,1].scatter(comparison_df['Pred Std'], comparison_df['Val R²'], s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    axes[0,1].annotate(row['Loss Function'], \n",
    "                      (row['Pred Std'], row['Val R²']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "axes[0,1].set_xlabel('Prediction Standard Deviation')\n",
    "axes[0,1].set_ylabel('Validation R²')\n",
    "axes[0,1].set_title('Prediction Diversity vs Accuracy\\n(Upper right is better)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Ranking comparison\n",
    "loss_names = comparison_df['Loss Function'].tolist()\n",
    "y_pos = np.arange(len(loss_names))\n",
    "\n",
    "axes[1,0].barh(y_pos, comparison_df['Middle %'], alpha=0.7, color='coral')\n",
    "axes[1,0].set_yticks(y_pos)\n",
    "axes[1,0].set_yticklabels(loss_names)\n",
    "axes[1,0].set_xlabel('Middle Clustering %')\n",
    "axes[1,0].set_title('Middle Clustering by Loss Function\\n(Lower is better)')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Composite score ranking\n",
    "balanced_ranking_display = balanced_ranking.copy()\n",
    "axes[1,1].barh(y_pos, balanced_ranking_display['Composite_Score'], alpha=0.7, color='lightblue')\n",
    "axes[1,1].set_yticks(y_pos)\n",
    "axes[1,1].set_yticklabels(balanced_ranking_display['Loss Function'])\n",
    "axes[1,1].set_xlabel('Composite Score (MSE + Middle %)')\n",
    "axes[1,1].set_title('Overall Performance Ranking\\n(Lower is better)')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS TO PREVENT MIDDLE VALUE CLUSTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get best performers in each category\n",
    "best_anti_middle = anti_middle_ranking.iloc[0]\n",
    "best_diversity = diversity_ranking.iloc[0]\n",
    "best_balanced = balanced_ranking.iloc[0]\n",
    "\n",
    "print(\"\\n🎯 TOP RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"\\n1. BEST ANTI-MIDDLE CLUSTERING: {best_anti_middle['Loss Function']}\")\n",
    "print(f\"   - Middle clustering: {best_anti_middle['Middle %']:.1f}%\")\n",
    "print(f\"   - Validation MSE: {best_anti_middle['Val MSE']:.4f}\")\n",
    "print(f\"   - Prediction diversity: {best_anti_middle['Pred Std']:.3f}\")\n",
    "\n",
    "print(f\"\\n2. HIGHEST PREDICTION DIVERSITY: {best_diversity['Loss Function']}\")\n",
    "print(f\"   - Prediction std: {best_diversity['Pred Std']:.3f}\")\n",
    "print(f\"   - Prediction range: {best_diversity['Pred Range']:.3f}\")\n",
    "print(f\"   - Validation MSE: {best_diversity['Val MSE']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. BEST OVERALL BALANCE: {best_balanced['Loss Function']}\")\n",
    "print(f\"   - Composite score: {best_balanced['Composite_Score']:.3f}\")\n",
    "print(f\"   - Validation MSE: {best_balanced['Val MSE']:.4f}\")\n",
    "print(f\"   - Middle clustering: {best_balanced['Middle %']:.1f}%\")\n",
    "\n",
    "print(\"\\n📋 IMPLEMENTATION STRATEGIES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\\n• Use weighted MSE with higher weights for extreme values\")\n",
    "print(\"• Implement anti-middle penalty in loss function\")\n",
    "print(\"• Add diversity regularization to encourage prediction spread\")\n",
    "print(\"• Consider focal loss for focusing on hard examples\")\n",
    "print(\"• Experiment with quantile loss for asymmetric penalties\")\n",
    "\n",
    "print(\"\\n⚠️  KEY INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"• Standard MSE tends to produce middle-clustered predictions\")\n",
    "print(\"• Custom loss functions can significantly reduce middle clustering\")\n",
    "print(\"• There's often a trade-off between accuracy and prediction diversity\")\n",
    "print(\"• Weighted and penalty-based losses show most promise\")\n",
    "\n",
    "print(\"\\n🚀 NEXT STEPS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"• Fine-tune the best-performing loss function hyperparameters\")\n",
    "print(\"• Test ensemble methods combining multiple loss functions\")\n",
    "print(\"• Implement data augmentation techniques\")\n",
    "print(\"• Consider architectural changes (e.g., multiple output heads)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad85b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and best models\n",
    "print(\"\\nSaving results and best models...\")\n",
    "\n",
    "# Save comparison results to CSV\n",
    "comparison_df.to_csv('../../data/loss_function_comparison.csv', index=False)\n",
    "print(\"✅ Comparison results saved to: data/loss_function_comparison.csv\")\n",
    "\n",
    "# Save the best model from each category\n",
    "best_models = {\n",
    "    'anti_middle': best_anti_middle['Loss Function'],\n",
    "    'diversity': best_diversity['Loss Function'], \n",
    "    'balanced': best_balanced['Loss Function']\n",
    "}\n",
    "\n",
    "for category, loss_name in best_models.items():\n",
    "    if loss_name in results:\n",
    "        model_path = f'../../exports/best_{category}_{loss_name}.keras'\n",
    "        results[loss_name]['model'].save(model_path)\n",
    "        print(f\"✅ Best {category} model ({loss_name}) saved to: {model_path}\")\n",
    "\n",
    "print(\"\\n📊 FINAL SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"• Tested {len(results)} different loss functions\")\n",
    "print(f\"• Best anti-middle: {best_anti_middle['Loss Function']} ({best_anti_middle['Middle %']:.1f}% clustering)\")\n",
    "print(f\"• Most diverse: {best_diversity['Loss Function']} (std: {best_diversity['Pred Std']:.3f})\")\n",
    "print(f\"• Best balanced: {best_balanced['Loss Function']} (score: {best_balanced['Composite_Score']:.3f})\")\n",
    "print(\"\\n🎉 Loss function analysis completed successfully!\")\n",
    "print(\"\\nUse the saved models and insights to improve your prediction diversity.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
